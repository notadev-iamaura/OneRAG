{
  "documents": [
    {
      "id": "faq-001",
      "title": "RAG 시스템이란?",
      "content": "RAG(Retrieval-Augmented Generation)는 검색 증강 생성 기술입니다. 사용자 질문에 대해 먼저 관련 문서를 검색한 후, 그 문서를 바탕으로 LLM이 답변을 생성합니다. 이를 통해 LLM의 환각(hallucination) 문제를 줄이고, 최신 정보나 기업 내부 데이터를 활용한 정확한 답변이 가능합니다.",
      "metadata": {
        "category": "기술 소개",
        "tags": ["RAG", "LLM", "검색"]
      }
    },
    {
      "id": "faq-002",
      "title": "하이브리드 검색의 장점",
      "content": "하이브리드 검색은 Dense 검색(의미 기반)과 Sparse 검색(키워드 기반, BM25)을 결합한 방식입니다. Dense 검색은 의미적으로 유사한 문서를 찾는 데 강하고, Sparse 검색은 정확한 키워드 매칭에 강합니다. 두 방식을 결합하면 '삼성전자 주가'와 같이 키워드가 중요한 질문과 '요즘 잘 나가는 IT 기업'과 같이 의미가 중요한 질문 모두에 효과적으로 대응할 수 있습니다.",
      "metadata": {
        "category": "기술 소개",
        "tags": ["하이브리드", "Dense", "Sparse", "BM25"]
      }
    },
    {
      "id": "faq-003",
      "title": "Weaviate 벡터 데이터베이스",
      "content": "Weaviate는 오픈소스 벡터 데이터베이스로, 하이브리드 검색을 기본 지원합니다. Docker로 쉽게 설치할 수 있고, GraphQL과 REST API를 제공합니다. RAG_Standard에서는 Weaviate를 기본 벡터 DB로 사용하며, 한국어 토크나이저(Kagome)를 활성화하여 한국어 검색 품질을 높였습니다.",
      "metadata": {
        "category": "인프라",
        "tags": ["Weaviate", "벡터DB", "Docker"]
      }
    },
    {
      "id": "faq-004",
      "title": "LLM Fallback 전략",
      "content": "RAG_Standard는 Multi-LLM Factory를 통해 여러 LLM 제공자(Google Gemini, OpenAI GPT, Anthropic Claude, OpenRouter)를 지원합니다. 주 LLM에 장애가 발생하면 설정된 순서대로 자동으로 다른 LLM으로 전환됩니다. 예를 들어 Google Gemini → OpenAI GPT → Anthropic Claude 순서로 폴백이 가능합니다.",
      "metadata": {
        "category": "기능",
        "tags": ["LLM", "Fallback", "고가용성"]
      }
    },
    {
      "id": "faq-005",
      "title": "GraphRAG 기능",
      "content": "GraphRAG는 문서 간의 관계를 그래프로 표현하여 검색 품질을 높이는 기술입니다. RAG_Standard의 GraphRAG는 NetworkX 기반 그래프 스토어에 벡터 검색을 통합하여, 'SAMSUNG'이라는 영문 쿼리로 '삼성전자' 노드를 찾을 수 있습니다. 이를 통해 관련 엔티티와 그 관계까지 함께 검색하여 더 풍부한 컨텍스트를 제공합니다.",
      "metadata": {
        "category": "기능",
        "tags": ["GraphRAG", "지식그래프", "엔티티"]
      }
    }
  ]
}
